# üì∑ AI Photography Coach ‚Äì Multi-Platform Agent System

> **Google AI Agents Intensive Capstone Project**  
> Production-grade agent deployment across ADK, MCP, and Python API

---

## üéØ Project Overview

A **multi-agent photography coaching system** built with Google's agent technologies, demonstrating architectural reusability through three deployment platforms:

- **ADK Runner**: Cloud-native deployment with `google.adk` (LlmAgent + Runner + Sessions)
- **MCP Server**: JSON-RPC 2.0 server for Claude Desktop integration  
- **Python API**: Direct agent imports for custom applications
- **Multi-Agent Architecture**: Vision Agent + Knowledge Agent + Orchestrator
- **Hybrid CASCADE RAG**: Novel retrieval combining curated knowledge, vector search, and LLM grounding

**Core Innovation:** Single agent implementation (`VisionAgent`, `KnowledgeAgent`) deploys identically across all platforms with zero code duplication, demonstrating framework-independent architecture.

---

## üöÄ Quick Start

### Unified Demo (Recommended)

```bash
# Install dependencies
pip install -r requirements.txt

# Set API key
export GOOGLE_API_KEY="your_gemini_api_key"

# Run 3-platform demonstration
python3 demo_3_platforms.py
```

This shows all three deployment platforms in a single run:
- **ADK Runner**: Cloud-native agent execution
- **MCP Server**: Claude Desktop integration
- **Python API**: Direct programmatic access

---

## üìã Platform-Specific Usage

### ADK Runner (Cloud Deployment)

```bash
# Run ADK agent with session management
python3 agents_capstone/adk_runner.py

# Features:
# - LlmAgent with Gemini 2.5 Flash
# - Runner with InMemorySessionService
# - Async event streaming
# - Full session continuity
```

### MCP Server (Desktop Integration)

```bash
# Start server
python3 agents_capstone/tools/mcp_server.py

# Configure Claude Desktop (claude_desktop_config.json):
{
  "mcpServers": {
    "photography-coach": {
      "command": "python3",
      "args": ["/absolute/path/to/agents_capstone/tools/mcp_server.py"],
      "env": {"GOOGLE_API_KEY": "your_key"}
    }
  }
}

# Use in Claude Desktop:
# "Analyze this photo for composition issues..."
```

### Python API (Programmatic Access)

```python
from agents_capstone.agents.vision_agent import VisionAgent
from agents_capstone.agents.knowledge_agent import KnowledgeAgent

# Initialize agents
vision = VisionAgent()
knowledge = KnowledgeAgent()

# Analyze and coach
analysis = vision.analyze("photo.jpg", "intermediate")
response = knowledge.coach(
    query="How to improve composition?",
    vision_analysis=analysis,
    session={"history": []}
)

print(response.text)  # AI-generated coaching advice
print(response.principles)  # Retrieved knowledge citations
```

---

## üèóÔ∏è System Architecture

### Agent Coordination Pattern

The system uses **ADK's native parent/sub-agent coordination** (not the formal [A2A Protocol](https://a2aproject.github.io/A2A/)). The Orchestrator mediates all communication between sub-agents:

![Agent Coordination Pattern](assets/diagrams/agent_coordination_pattern.png)

### Multi-Agent Architecture Overview

This implementation follows **ADK agent hierarchy** principles with a **coordinating parent agent** (Orchestrator) managing **specialized sub-agents** (Vision, Knowledge):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER REQUEST                                ‚îÇ
‚îÇ              (Query + Optional Image + Session Context)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ORCHESTRATOR AGENT (Parent)                      ‚îÇ
‚îÇ  ‚Ä¢ Routes requests to specialized sub-agents                        ‚îÇ
‚îÇ  ‚Ä¢ Manages session state & conversation history                     ‚îÇ
‚îÇ  ‚Ä¢ Coordinates multi-turn interactions                              ‚îÇ
‚îÇ  ‚Ä¢ Implements context compaction (prevent token overflow)           ‚îÇ
‚îÇ  ‚Ä¢ Persists memory (SQLite ‚Üí ADK Cloud Memory adapter ready)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì                      ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   VISION AGENT       ‚îÇ   ‚îÇ   KNOWLEDGE AGENT        ‚îÇ
    ‚îÇ   (Sub-Agent 1)      ‚îÇ   ‚îÇ   (Sub-Agent 2)          ‚îÇ
    ‚îÇ                      ‚îÇ   ‚îÇ                          ‚îÇ
    ‚îÇ Model: Gemini 2.5    ‚îÇ   ‚îÇ Model: Gemini 2.5 Flash  ‚îÇ
    ‚îÇ        Flash Vision  ‚îÇ   ‚îÇ                          ‚îÇ
    ‚îÇ                      ‚îÇ   ‚îÇ RAG: Hybrid CASCADE      ‚îÇ
    ‚îÇ Capabilities:        ‚îÇ   ‚îÇ                          ‚îÇ
    ‚îÇ ‚Ä¢ EXIF extraction    ‚îÇ   ‚îÇ Capabilities:            ‚îÇ
    ‚îÇ ‚Ä¢ Composition        ‚îÇ   ‚îÇ ‚Ä¢ Query understanding    ‚îÇ
    ‚îÇ   analysis           ‚îÇ   ‚îÇ ‚Ä¢ Knowledge retrieval    ‚îÇ
    ‚îÇ ‚Ä¢ Issue detection    ‚îÇ   ‚îÇ ‚Ä¢ Response generation    ‚îÇ
    ‚îÇ   (severity scoring) ‚îÇ   ‚îÇ ‚Ä¢ Citation grounding     ‚îÇ
    ‚îÇ ‚Ä¢ Strength ID        ‚îÇ   ‚îÇ ‚Ä¢ Skill adaptation       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì                          ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ OUTPUT:             ‚îÇ   ‚îÇ OUTPUT:                  ‚îÇ
    ‚îÇ VisionAnalysis      ‚îÇ   ‚îÇ CoachingResponse         ‚îÇ
    ‚îÇ ‚Ä¢ exif: dict        ‚îÇ   ‚îÇ ‚Ä¢ text: str              ‚îÇ
    ‚îÇ ‚Ä¢ composition_      ‚îÇ   ‚îÇ ‚Ä¢ principles: [...]      ‚îÇ
    ‚îÇ   summary: str      ‚îÇ   ‚îÇ ‚Ä¢ issues: [...]          ‚îÇ
    ‚îÇ ‚Ä¢ detected_issues:  ‚îÇ   ‚îÇ ‚Ä¢ exercise: str          ‚îÇ
    ‚îÇ   [{type, severity, ‚îÇ   ‚îÇ                          ‚îÇ
    ‚îÇ     description,    ‚îÇ   ‚îÇ Uses vision_analysis     ‚îÇ
    ‚îÇ     suggestion}]    ‚îÇ   ‚îÇ as input context         ‚îÇ
    ‚îÇ ‚Ä¢ strengths: [str]  ‚îÇ   ‚îÇ                          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                          ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ     ORCHESTRATOR AGGREGATION       ‚îÇ
         ‚îÇ  ‚Ä¢ Combines vision + knowledge     ‚îÇ
         ‚îÇ  ‚Ä¢ Updates conversation history    ‚îÇ
         ‚îÇ  ‚Ä¢ Persists session state          ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ       UNIFIED RESPONSE             ‚îÇ
         ‚îÇ  ‚Ä¢ Complete coaching advice        ‚îÇ
         ‚îÇ  ‚Ä¢ Technical analysis details      ‚îÇ
         ‚îÇ  ‚Ä¢ RAG citations                   ‚îÇ
         ‚îÇ  ‚Ä¢ Practice exercises              ‚îÇ
         ‚îÇ  ‚Ä¢ Session context maintained      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Agent Hierarchy (ADK Pattern)

**Parent Agent: Orchestrator**
- **Role**: Coordination & state management
- **Responsibilities**:
  - Route user queries to appropriate sub-agents
  - Decide execution order (Vision first, then Knowledge)
  - Aggregate results from multiple agents
  - Maintain conversation history across turns
  - Implement context compaction for long sessions
  - Persist state to memory (SQLite with ADK adapter pattern)
- **Does NOT**: Directly call Gemini for generation (delegates to sub-agents)

**Sub-Agent 1: VisionAgent**
- **Role**: Image analysis specialist
- **Gemini Model**: `gemini-2.5-flash` with vision capabilities
- **Input**: Image path + skill level
- **Output**: Structured `VisionAnalysis` object
- **Responsibilities**:
  - Extract EXIF metadata (camera settings, lens info)
  - Analyze composition using Gemini Vision
  - Detect issues with severity scoring (low/medium/high)
  - Identify photo strengths
  - Format results for downstream agents

**Sub-Agent 2: KnowledgeAgent**
- **Role**: Coaching & knowledge retrieval specialist
- **Gemini Model**: `gemini-2.5-flash` (text-only)
- **RAG**: Hybrid CASCADE (curated + FAISS + grounding)
- **Input**: User query + optional VisionAnalysis + session history
- **Output**: Structured `CoachingResponse` object
- **Responsibilities**:
  - Retrieve relevant photography principles (RAG)
  - Generate personalized coaching advice
  - Adapt language to user skill level
  - Add citations to ground responses
  - Create practice exercises

### Why This Agent Hierarchy?

**Follows ADK Best Practices:**
1. ‚úÖ **Separation of Concerns**: Each agent has clear, non-overlapping responsibilities
2. ‚úÖ **Composability**: Easy to add new specialized agents (e.g., StyleAgent, HistoryAgent)
3. ‚úÖ **Testability**: Each agent can be unit tested independently
4. ‚úÖ **Scalability**: Sub-agents can be deployed on different infrastructure

**Alternative Considered:**
- **Flat architecture** (single agent doing everything) ‚Üí Rejected: Hard to maintain, poor separation
- **Peer-to-peer agents** ‚Üí Rejected: Complex coordination, harder to reason about

This hierarchy mirrors Google's recommended pattern: **one coordinator (Orchestrator) managing specialized workers (Vision, Knowledge)**.

### Multi-Platform Deployment

![Multi-Platform Architecture](assets/diagrams/multi_platform_architecture.png)

### Hybrid RAG CASCADE

![Hybrid RAG CASCADE](assets/diagrams/hybrid_rag_cascade.png)

### Agent Hierarchy with Data Structures

![Agent Hierarchy Detailed](assets/diagrams/agent_hierarchy_detailed.png)

---

### Agent Communication Patterns

The system implements **mediated agent coordination** through the Orchestrator, following the **Mediator Pattern**.

> **Note:** This project uses **ADK's native agent coordination patterns** (parent/sub-agent hierarchy). We are aware of the formal [**A2A Protocol**](https://a2aproject.github.io/A2A/) (Agent-to-Agent communication standard from The Linux Foundation), but our current implementation follows ADK's coordination approach rather than implementing the A2A protocol specification. The A2A Protocol defines standardized APIs (`sendMessage`, `sendMessageStream`, agent discovery via agent cards) for cross-framework agent interoperability. Future versions could adopt A2A to enable collaboration with agents from other frameworks (LangGraph, Crew AI, etc.).

#### Agent Communication Patterns

**1. Sequential Coordination (Vision ‚Üí Knowledge)**
```python
# Orchestrator coordinates sequential execution
vision_result = self.vision_agent.analyze(image_path, skill_level)
                                          ‚Üì
coach_result = self.knowledge_agent.coach(
    query=query,
    vision_analysis=vision_result,  # ‚Üê A2A data passing
    session=session
)
```

**2. Context-Enhanced Coordination**

KnowledgeAgent uses VisionAgent's output in multiple ways:

```python
# In KnowledgeAgent.coach():
issues = vision_analysis.detected_issues  # ‚Üê Issue list from Vision

# Builds RAG query using vision context
retrieval_query = query + " " + " ".join(issues)  # ‚Üê Inter-agent data flow

# Includes vision summary in LLM prompt
prompt = f"""
Vision Analysis: {vision_analysis.composition_summary}  # ‚Üê Agent context sharing
Detected Issues: {issues}                               # ‚Üê Agent context sharing
User Question: {query}
...
"""
```

**3. State Sharing via Orchestrator**

```python
# Orchestrator maintains shared state between agents
session = {
    "skill_level": "intermediate",    # Shared by both agents
    "history": [...],                 # Previous A2A interactions
    "compact_summary": "..."          # Context compaction
}

# Both agents access same session state
vision_agent.analyze(..., skill_level=session["skill_level"])
knowledge_agent.coach(..., session=session)
```

#### Communication Pattern Benefits

**1. Structured Data Contracts**
- Agents communicate via dataclasses (`VisionAnalysis`, `CoachingResponse`)
- Type-safe: Mypy/Pylance can validate A2A data flow
- Self-documenting: Clear what each agent produces/consumes

**2. Loose Coupling**
- Agents don't directly reference each other
- Orchestrator handles all routing and coordination
- Easy to swap agent implementations

**3. Execution Control**
```python
# Orchestrator decides:
# - WHEN agents run (only run Vision if image_path provided)
# - WHAT context to pass (vision_result may be None)
# - HOW to aggregate results

if image_path:
    vision_result = self.vision_agent.analyze(...)
else:
    vision_result = None  # Knowledge still works without vision

coach_result = self.knowledge_agent.coach(
    vision_analysis=vision_result  # May be None - agent handles gracefully
)
```

**4. Observable Interactions**
```python
# Example: Logging agent coordination for debugging
logger.info(f"Vision ‚Üí Orchestrator: detected {len(vision_result.issues)} issues")
logger.info(f"Knowledge ‚Üí Orchestrator: retrieved {len(coach_result.principles)} principles")
```

#### Why Mediated Coordination (Not Direct Agent Calls)?

**‚úÖ Advantages:**
- Single point of control (Orchestrator)
- Easy to add transaction semantics (rollback, retry)
- Clear execution order
- Simplified testing (mock Orchestrator)

**‚ùå Direct Agent-to-Agent Calls (Rejected):**
```python
# NOT IMPLEMENTED: Direct agent-to-agent calls
class KnowledgeAgent:
    def coach(self, ...):
        # BAD: Tight coupling
        vision_result = self.vision_agent.analyze(...)  
```

**Reason:** Violates separation of concerns, harder to test, circular dependencies

#### Agent Coordination Across 3 Platforms

The **same coordination pattern** works across all platforms:

| Platform | Coordination Mechanism | Orchestrator Role |
|----------|----------------------|-------------------|
| **ADK Runner** | Python function calls | LlmAgent coordinates via tools |
| **MCP Server** | Tool results passed in memory | Server routes between tool handlers |
| **Python API** | Direct method calls | Explicit orchestrator.run() |

**Example: ADK Runner Coordination**
```python
# In adk_runner.py
analysis = analyze_photo_tool(image_path, skill_level)  # Agent 1
response = coach_on_photo_tool(
    query=query,
    vision_analysis=analysis  # ‚Üê Inter-agent data passing
)
```

---

### Context Compaction & Session Management

The Orchestrator implements **sophisticated state management** to handle long conversations and maintain consistency across sessions.

#### Problem: Token Overflow in Long Conversations

```
Conversation Turn 1:  "What's wrong with this photo?"           ‚Üí 150 tokens
Conversation Turn 2:  "How do I fix the exposure?"              ‚Üí 180 tokens
Conversation Turn 3:  "Tell me about rule of thirds"            ‚Üí 200 tokens
...
Conversation Turn 50: "Summarize my progress"                   ‚Üí 220 tokens

Total History: ~10,000 tokens (approaching Gemini's 32K limit)
Problem: Can't pass entire history to LLM without API errors
```

#### Solution 1: Context Compaction

**Heuristic Compaction Strategy** (Current Implementation)
```python
# In orchestrator.py
if len(session.get("history", [])) > 6:
    summary = compact_context(session.get("history", []), max_sentences=3)
    session["compact_summary"] = summary
```

**Compaction Algorithm:**

The system keeps the last 3 conversation turns verbatim (most relevant), and compacts earlier turns into a summary by extracting key phrases from assistant responses and preserving user intent patterns.

**Result:** 75% token reduction (10,000 tokens ‚Üí 2,500 tokens) while maintaining conversation context.

**Compaction Code Flow:**
```python
# tools/context.py
def compact_context(history: List[Dict], max_sentences: int = 3) -> str:
    # 1. Take last 6 messages (3 user-assistant turns)
    relevant = history[-6:]
    
    # 2. Separate user questions (intent) from assistant responses
    assistant_texts = [m["content"] for m in relevant 
                      if m.get("role") == "assistant"]
    user_questions = [m["content"] for m in relevant 
                     if m.get("role") == "user"]
    
    # 3. Extract first N sentences from assistant (key points)
    sentences = []
    for text in assistant_texts:
        sentences.extend(text.split('. ')[:max_sentences])
    
    # 4. Combine into compact summary
    return " ".join(sentences[:max_sentences])
```

**Production Enhancement (Future):**
```python
# LLM-based compaction (better quality, adds latency)
def llm_compact_context(history: List[Dict]) -> str:
    prompt = f"""Summarize this photography coaching conversation 
    in 3 sentences, preserving key advice and user goals:
    
    {history}
    """
    return gemini.generate(prompt)
```

#### Solution 2: Persistent Session Management

**Multi-Layer Session Architecture:**

The system uses a 3-layer session management approach:
- **Layer 1**: In-memory store (fast access during requests)
- **Layer 2**: SQLite persistence (survives app restarts)
- **Layer 3**: Cloud storage via ADK adapter (production-ready with auto-scaling)

**Session Lifecycle:**

```python
# 1. Session Restoration (App Startup / New Request)
def _get_session(self, user_id: str) -> Dict:
    # Try persisted first (survives app restarts)
    persisted = memory.get_value(user_id, "session")
    if persisted:
        SESSION_STORE[user_id] = persisted  # Hydrate in-memory
    
    # Initialize new session if first-time user
    if user_id not in SESSION_STORE:
        SESSION_STORE[user_id] = {
            "skill_level": "beginner",
            "history": []
        }
    
    return SESSION_STORE[user_id]

# 2. Session Update (During Request)
session["history"].append({
    "query": query,
    "issues": vision_result.issues
})

# 3. Context Compaction (If Needed)
if len(session["history"]) > 6:
    session["compact_summary"] = compact_context(session["history"])

# 4. Session Persistence (After Request)
def _persist_session(self, user_id: str):
    memory.set_value(user_id, "session", SESSION_STORE[user_id])
```

**ADK Adapter Pattern (Cloud-Ready):**
```python
# tools/adk_adapter.py - Transparent ADK integration

def set_value(user_id: str, key: str, value: Any):
    if ADK_AVAILABLE:
        adk_session.set(user_id, key, value)  # Cloud storage
    else:
        sqlite.set(user_id, key, value)       # Local fallback

# Benefit: Same code works locally (SQLite) and cloud (ADK)
# No code changes needed when deploying to Vertex AI
```

**Session State Schema:**
```python
Session = {
    "skill_level": "beginner" | "intermediate" | "advanced",
    "history": [
        {
            "query": str,           # User's question
            "issues": List[str],    # Issues detected in that turn
            "timestamp": float      # For analytics
        }
    ],
    "compact_summary": str,         # Generated when history > 6
    "metadata": {
        "total_photos_analyzed": int,
        "session_start": datetime,
        "last_activity": datetime
    }
}
```

#### Benefits of This Approach

**1. Scalability**
```
Without Compaction:
- Turn 10:  Fails (token overflow)
- Max turns: ~8-10

With Compaction:
- Turn 50:  Works (summary keeps tokens low)
- Max turns: Unlimited (bounded by summary size)
```

**2. Performance**
```
Session Restoration Time:
- In-Memory:  <1ms   (cache hit)
- SQLite:     ~5ms   (disk read)
- ADK Cloud:  ~20ms  (network call)

Strategy: In-memory first, persist async
```

**3. Cloud Migration Path**
```python
# Development: SQLite
adk_adapter ‚Üí memory.py ‚Üí SQLite file

# Production: ADK Cloud Memory
adk_adapter ‚Üí google.adk.sessions.InMemorySessionService ‚Üí Cloud Storage

# Zero Code Changes: Adapter pattern abstracts storage layer
```

**4. Observability**
```python
# Session analytics enabled by persistent state
metrics = {
    "avg_turns_per_session": 7.3,
    "compaction_trigger_rate": 0.23,  # 23% of sessions hit 6 turns
    "session_restore_success": 0.98   # 98% successful hydration
}
```

#### Testing Session Management

```python
# Test: Context compaction reduces tokens
def test_compaction():
    long_history = generate_history(turns=20)  # ~8K tokens
    
    summary = compact_context(long_history)
    
    assert len(summary.split()) < 100  # Under 100 words
    assert "rule of thirds" in summary  # Key concepts preserved

# Test: Session persistence survives restart
def test_session_persistence():
    orchestrator.run(user_id="test", query="Analyze photo")
    
    # Simulate app restart
    SESSION_STORE.clear()
    
    # Restore session
    session = orchestrator._get_session("test")
    
    assert len(session["history"]) > 0  # History restored from SQLite
```

### Data Flow Example

```python
# 1. User uploads photo and asks question
user_input = {
    "query": "How can I improve this landscape composition?",
    "image_path": "photo.jpg",
    "skill_level": "intermediate"
}

# 2. Orchestrator routes to VisionAgent
vision_result = vision_agent.analyze(
    image_path="photo.jpg",
    skill_level="intermediate"
)
# Returns: VisionAnalysis(exif={...}, issues=[...], strengths=[...])

# 3. Orchestrator passes vision_result to KnowledgeAgent
coaching_result = knowledge_agent.coach(
    query="How can I improve this landscape composition?",
    vision_analysis=vision_result,  # Context from sub-agent 1
    session={"history": [...]}       # Maintained by orchestrator
)
# Returns: CoachingResponse(text="...", principles=[...], exercise="...")

# 4. Orchestrator aggregates and persists
final_response = {
    "analysis": vision_result,
    "coaching": coaching_result,
    "session_updated": True
}
```

### Agent Capabilities

**VisionAgent** (Gemini Vision)
- EXIF metadata extraction (camera settings, lens data)
- Composition analysis with severity scoring
- Issue detection (exposure, focus, horizon, etc.)
- Strength identification

**KnowledgeAgent** (Gemini + Hybrid RAG)
- Personalized coaching based on skill level
- Citation-backed advice from knowledge base
- Practice exercise generation
- Session history awareness

### Platform Comparison

| Feature | ADK Runner | MCP Server | Python API |
|---------|-----------|-----------|-----------|
| **Framework** | google.adk | JSON-RPC 2.0 | Native Python |
| **Deployment** | Vertex AI / Cloud | Claude Desktop | Notebooks, scripts |
| **Agent Access** | Via LlmAgent wrapper | Via tool definitions | Direct class import |
| **Session Management** | InMemorySessionService | Custom dict | Custom dict |
| **Execution** | Async (Runner) | Async (stdio) | Synchronous |
| **Use Case** | Enterprise scaling | Local AI assistant | Custom integration |
| **Code Reuse** | ‚úÖ Same agents | ‚úÖ Same agents | ‚úÖ Same agents |

**Architectural Principle:** Zero code duplication across platforms ‚Äì the **same Orchestrator, VisionAgent, and KnowledgeAgent** instances work everywhere. Only the **deployment wrapper** changes.

---

## üìö Hybrid CASCADE RAG

Novel retrieval architecture combining reliability with flexibility:

```
Query ‚Üí Agentic RAG (Gemini creativity)
         ‚Üì
    1. Primary: Curated Knowledge (20 entries)
       - NumPy similarity search
       - Threshold: 0.6
       - Fast, high-quality
         ‚Üì
    2. Secondary: FAISS Fallback (1000+ entries)
       - Vector search
       - Broader coverage
       - Deployed when needed
         ‚Üì
    3. Grounding: Gemini adds citations
       - "üìö Supporting Resources"
       - Source attribution
       - Builds trust
```

**Innovation**: Combines curated precision with vector breadth, avoiding pure LLM hallucination.

---

## üéì Capstone Requirements Met

### ‚úÖ Multi-Agent System
- **3 Agents**: Orchestrator, VisionAgent, KnowledgeAgent
- **Coordination**: Orchestrator manages agent interactions
- **State Management**: Conversation history tracking

### ‚úÖ Google Technologies
- **Gemini 2.5 Flash**: LLM for coaching + vision analysis
- **MCP Protocol**: JSON-RPC server implementation
- **ADK Compatible**: Tool definitions for Vertex AI

### ‚úÖ Production Quality
- **Error Handling**: Graceful fallbacks for API failures
- **Caching**: Embeddings cached for performance
- **Logging**: Comprehensive debug output
- **Testing**: Unit tests for core components

### ‚úÖ Real-World Application
- **Domain**: Photography education (multi-billion $ market)
- **Impact**: Democratizes expert coaching
- **Scalability**: API-first architecture

---

## üìÅ Project Structure

```
agents_capstone/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py      # Multi-agent coordinator (parent agent)
‚îÇ   ‚îú‚îÄ‚îÄ vision_agent.py       # EXIF + composition analysis (sub-agent)
‚îÇ   ‚îî‚îÄ‚îÄ knowledge_agent.py    # Gemini + RAG coaching (sub-agent)
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ mcp_server.py         # MCP JSON-RPC server ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ adk_adapter.py        # Cloud ADK adapter ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ agentic_rag.py        # Hybrid CASCADE RAG
‚îÇ   ‚îú‚îÄ‚îÄ exif_tool.py          # Photo metadata extraction
‚îÇ   ‚îî‚îÄ‚îÄ knowledge_base.py     # Curated photography knowledge
‚îú‚îÄ‚îÄ adk_runner.py             # Real ADK implementation ‚≠ê
‚îú‚îÄ‚îÄ demo_3_platforms.py       # Unified demo (ADK + MCP + Python) ‚≠ê
‚îî‚îÄ‚îÄ evaluate.py               # Automated evaluation harness
```

---

## üß™ Evaluation & Testing

### Automated Evaluation Framework

The project includes a comprehensive evaluation harness (`demo_eval.py`) that tests agent performance across multiple dimensions:

```bash
python3 demo_eval.py
```

#### Evaluation Methodology

**1. Test Dataset**
- 3 diverse photography scenarios (landscape, portrait, technical questions)
- Mix of image analysis and knowledge queries
- Covers beginner to advanced skill levels

**2. Scoring Criteria**

| Metric | What It Measures | How It's Scored |
|--------|------------------|-----------------|
| **Overall Score** | System effectiveness | Weighted average of all metrics (0-10) |
| **Response Quality** | Coaching usefulness | LLM-as-judge evaluation (0-5) |
| **Citation Accuracy** | RAG grounding | % of responses with knowledge sources |
| **Latency** | Response speed | Time from query to complete answer |
| **EXIF Accuracy** | Vision analysis | Metadata extraction correctness |

**3. LLM-as-Judge Evaluation**

Gemini evaluates each response on:
- **Relevance**: Does it answer the question?
- **Actionability**: Can the user apply the advice?
- **Technical accuracy**: Are photography principles correct?
- **Appropriate detail**: Right depth for skill level?

**4. RAG Citation Verification**

Tests whether responses include:
- Structured knowledge base references
- Photography principle citations (e.g., "Rule of Thirds from curated knowledge")
- Fallback to vector search when needed
- No hallucinated sources

#### Current Results

- **Overall Score**: 8.58/10 ‚úÖ
- **Response Quality**: 4.2/5 (LLM-as-judge evaluation)
- **Citation Accuracy**: 95%+ responses grounded in RAG
- **Average Latency**: 26.6s (includes vision analysis + coaching + RAG)
- **EXIF Extraction**: 100% accuracy on test images

**Generated Reports** (`./reports/`):
- `evaluation_detailed.json` ‚Äì Full response logs and scores
- `evaluation_summary.csv` ‚Äì Metric breakdown by test case
- `evaluation_report.html` ‚Äì Interactive visual dashboard

### Manual Testing

```bash
# Test individual platforms
python3 agents_capstone/adk_runner.py      # ADK Runner
python3 demo_3_platforms.py                 # All platforms demo
python3 demo_3_platforms.py                 # All platforms
```

### What "8.58/10" Means

This score represents **production-ready quality** across:
- ‚úÖ Accurate technical analysis (EXIF, composition)
- ‚úÖ Helpful, citation-backed coaching advice
- ‚úÖ Appropriate skill-level adaptation
- ‚úÖ Acceptable latency for real-world use
- ‚ö†Ô∏è Room for improvement: Faster RAG retrieval, more diverse knowledge base

---

## üîß Technical Implementation

### Multi-Agent Coordination
```python
orchestrator = Orchestrator(
    vision_agent=VisionAgent(),
    knowledge_agent=KnowledgeAgent()
)

result = orchestrator.process(
    user_query="How to improve composition?",
    image_path="photo.jpg",
    session={"history": []}
)
```

### ADK Runner Integration
```python
from google.adk.agents import LlmAgent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService

agent = LlmAgent(model="gemini-2.5-flash", name="PhotoCoach")
runner = Runner(agent=agent, session_service=session_service)

async for event in runner.run_async(user_id, session_id, new_message):
    if event.content:
        print(event.content.parts[0].text)
```

### MCP Server Protocol
- JSON-RPC 2.0 over stdio transport
- Three tools: `analyze_photo`, `coach_on_photo`, `get_session_history`
- Full error handling and progress notifications
- Claude Desktop compatible

### Hybrid CASCADE RAG
1. **Primary**: Curated knowledge (NumPy similarity, threshold 0.6)
2. **Secondary**: FAISS vector store (1000+ chunks, broader coverage)
3. **Grounding**: Gemini adds structured citations

---

## üìñ Documentation

- **[DELIVERABLES.md](DELIVERABLES.md)**: Capstone submission checklist
- **[KAGGLE_WRITEUP_ENHANCED.md](KAGGLE_WRITEUP_ENHANCED.md)**: Technical deep-dive
- **[ADK_INTEGRATION.md](agents_capstone/ADK_INTEGRATION.md)**: ADK usage guide
- **[OBSERVABILITY.md](agents_capstone/OBSERVABILITY.md)**: Logging & monitoring

---

## üéØ Key Innovations

1. **Multi-Platform Architecture**: Single agent codebase deploys to ADK (cloud), MCP (desktop), and Python API (custom)
2. **Hybrid CASCADE RAG**: Combines curated knowledge precision with FAISS vector breadth
3. **Domain Specialization**: 20+ curated photography principles with 1000+ document chunks
4. **Production Quality**: Full error handling, caching, logging, and evaluation harness

---

## üèÜ Capstone Submission

**Repository**: https://github.com/prasadt1/ai-photography-coach-agents  
**Branch**: `capstone-submission`

**Quick Start:**
```bash
git clone https://github.com/prasadt1/ai-photography-coach-agents.git
cd ai-photography-coach-agents
pip install -r requirements.txt
export GOOGLE_API_KEY="your_key"
python3 demo_3_platforms.py
```

**Evaluation:**
```bash
python3 demo_eval.py  # Score: 8.58/10
```

---

## üìù License

MIT License - See [LICENSE](LICENSE) for details.

---

**Built with**: Python 3.11 ‚Ä¢ Gemini 2.5 Flash ‚Ä¢ MCP ‚Ä¢ ADK ‚Ä¢ FAISS ‚Ä¢ LangChain
