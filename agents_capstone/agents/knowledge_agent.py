"""
KnowledgeAgent: LLM-powered coaching agent using Gemini 1.5 Flash.

Responsibilities:
1. Generate personalized coaching responses based on user queries
2. Incorporate vision analysis results (issues, EXIF data)
3. Maintain conversation context across multiple turns
4. Retrieve relevant photography principles from knowledge base
5. Create actionable practice exercises

Key Innovation: This is NOT a template-based system. Every response is dynamically
generated by Gemini 1.5 Flash, enabling nuanced, context-aware coaching that adapts
to user's specific situation and conversation history.

Model Choice: Gemini 1.5 Flash chosen for:
- Fast response times (<2s typical latency)
- Strong instruction following for coaching scenarios
- Good balance of quality and cost for production deployment
"""

from dataclasses import dataclass
from typing import List, Optional, Dict, Any

import google.generativeai as genai
from agents_capstone.tools.knowledge_base import simple_retrieve, Principle

@dataclass
class CoachingResponse:
    """Structured coaching output for UI rendering.
    
    This format provides everything the Streamlit UI needs to display
    a complete coaching interaction.
    """
    text: str  # Main coaching response from Gemini LLM
    principles: List[Principle]  # Referenced photography principles
    issues: List[str]  # Issues from vision analysis
    exercise: str  # Practice exercise for skill improvement

class KnowledgeAgent:
    """Turns analysis + question + history into coaching text using LLM.
    
    Architecture: This agent is stateless - all context is passed in through
    the session parameter. The Orchestrator manages state persistence.
    """

    def coach(
        self,
        query: str,
        vision_analysis: Optional[object],
        session: dict,
    ) -> CoachingResponse:
        """Generate coaching response using LLM with conversation context.
        
        Coaching Pipeline:
        1. Extract issues from vision analysis
        2. Build conversation history context (last 3 turns)
        3. Retrieve relevant photography principles from knowledge base
        4. Call Gemini 1.5 Flash with structured prompt
        5. Generate practice exercise based on issues
        
        Args:
            query: User's current question/request
            vision_analysis: Optional VisionAnalysis from VisionAgent
            session: Dict with conversation history and user metadata
            
        Returns:
            CoachingResponse with LLM text, principles, issues, and exercise
        """
        # Step 1: Extract issues detected by VisionAgent
        issues: List[str] = []
        if vision_analysis is not None:
            issues = list(getattr(vision_analysis, "issues", []))

        # Step 2: Build conversation context from history
        # Design: Only last 3 turns included to prevent token overflow
        # Orchestrator handles longer-term context compaction
        history_context = self._build_history_context(session)
        
        # Step 3: Retrieve relevant principles from knowledge base
        # Simple RAG: Combines user query + detected issues for semantic search
        retrieval_query = query + " " + " ".join(issues)
        principles = simple_retrieve(retrieval_query)
        
        # Step 4: Get dynamic response from Gemini 1.5 Flash
        # Key: This is NOT a template - every response is freshly generated
        coaching_text = self._get_llm_coaching(
            query=query,
            issues=issues,
            history=history_context,
            principles=principles,
        )

        # Step 5: Generate actionable practice exercise
        exercise = self._generate_exercise(issues)

        return CoachingResponse(
            text=coaching_text,
            principles=principles,
            issues=issues,
            exercise=exercise,
        )

    def _build_history_context(self, session: Dict[str, Any]) -> str:
        """Build context string from conversation history.
        
        Context Window Strategy:
        - Only last 3 turns included (prevents token overflow)
        - Each turn includes the user's query
        - Orchestrator handles longer-term summarization via compact_context()
        
        Args:
            session: Dict containing conversation history
            
        Returns:
            Formatted string of recent conversation for LLM prompt
        """
        history = session.get("history", [])
        if not history:
            return "This is the start of the conversation."
        
        context_lines = []
        for i, entry in enumerate(history[-3:]):  # Last 3 turns for context
            query = entry.get("query", "")
            if query:
                context_lines.append(f"- Previous question {i+1}: {query}")
        
        return "\n".join(context_lines) if context_lines else "This is the start of the conversation."

    def _get_llm_coaching(
        self,
        query: str,
        issues: List[str],
        history: str,
        principles: List[Principle],
    ) -> str:
        """Get coaching response from Gemini LLM.
        
        Prompt Engineering Strategy:
        - Structured sections (Question, Issues, Principles, History)
        - Clear coaching guidelines (specific, actionable, concise)
        - Persona instruction ("friendly photography coach")
        - Context limits (3-4 sentences) to maintain focus
        
        Model: gemini-1.5-flash chosen for speed and quality balance
        Fallback: Template-based response if API fails (prevents UI errors)
        
        Args:
            query: User's current question
            issues: List of detected photo issues
            history: Formatted conversation context
            principles: Retrieved photography principles
            
        Returns:
            LLM-generated coaching text or fallback response
        """
        try:
            # Build principles context from knowledge base retrieval
            principles_text = "\n".join([
                f"- {p.topic}: {p.text}" for p in principles[:3]
            ]) if principles else "No specific principles found."

            # Structured prompt with clear sections and coaching guidelines
            prompt = f"""You are an expert photography coach providing personalized guidance.

User's Current Question: {query}

Detected Issues in Photo:
{chr(10).join(f"- {issue}" for issue in issues) if issues else "- No issues detected"}

Photography Principles to Consider:
{principles_text}

Conversation Context (Previous Questions):
{history}

Provide helpful, specific photography coaching that:
1. Directly addresses the user's current question
2. References any detected issues in the photo
3. Gives actionable advice they can apply immediately
4. Builds on previous conversation context if applicable
5. Stays focused and concise (3-4 sentences)

Respond as a friendly photography coach, not as a template."""

            # Call Gemini API (using latest flash model)
            # Note: API key configured via environment variable GOOGLE_API_KEY
            model = genai.GenerativeModel("gemini-2.5-flash")
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            # Fallback if LLM fails (API errors, rate limits, network issues)
            # Log the error for debugging
            import sys
            print(f"DEBUG KnowledgeAgent LLM error: {type(e).__name__}: {str(e)[:200]}", file=sys.stderr)
            return self._generate_fallback_response(query, issues)

    def _generate_fallback_response(self, query: str, issues: List[str]) -> str:
        """Generate fallback response if LLM is unavailable.
        
        Fallback Strategy: Simple keyword matching for common photography topics
        This ensures the UI always displays something useful even during API failures.
        
        Production Note: In deployed system, fallback responses logged for monitoring
        
        Args:
            query: User's question
            issues: Detected photo issues
            
        Returns:
            Template-based coaching response
        """
        response = f"Based on your question about {query}:\n\n"
        
        # Pattern matching for common photography topics
        if "composition" in query.lower():
            response += "For composition: "
            if "subject_centered" in issues:
                response += "Try moving your main subject to the rule of thirds. "
            response += "Check your horizon line and use leading lines to guide the viewer."
        elif "lighting" in query.lower():
            response += "Lighting is key to great photos. Look for directional light, avoid harsh shadows, and consider the time of day."
        elif "iso" in query.lower() or "settings" in query.lower():
            response += "Adjust ISO based on available light - lower ISO for bright conditions, higher for low light. Balance with aperture and shutter speed."
        elif "about" in query.lower() or "subject" in query.lower():
            response += "Your photo shows interesting elements. Focus on what draws your eye most, and frame to emphasize that."
        else:
            response += "Great question about photography. Keep practicing and experimenting with different perspectives and settings."
        
        return response

    def _generate_exercise(self, issues: List[str]) -> str:
        """Generate a practice exercise based on detected issues.
        
        Exercise Strategy: Map each issue type to targeted practice activity
        Goal: Provide actionable next steps for skill improvement
        
        Future Enhancement: Use LLM to generate personalized exercises
        based on user's skill level and specific photo characteristics
        
        Args:
            issues: List of detected photo issues
            
        Returns:
            Actionable practice exercise string
        """
        # Map issues to targeted exercises
        if "subject_centered" in issues:
            return "Exercise: Take 10 photos of the same scene. For each frame, place the subject on a different position using the rule of thirds. Review which feels most compelling."
        elif "shallow_depth_of_field" in issues:
            return "Exercise: Practice focus placement with a wide aperture. Take shots with focus on different elements to master depth control."
        else:
            # Default exercise for general improvement
            return "Exercise: Spend 30 minutes taking photos of one subject from different angles, distances, and compositions. Note what works best."
