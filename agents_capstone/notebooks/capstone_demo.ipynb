{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143018ba",
   "metadata": {},
   "source": [
    "## Setup: Configure Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path('/Users/prasadt1/ai-photography-coach-rag')\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set API key (replace with your own)\n",
    "os.environ['GOOGLE_API_KEY'] = os.environ.get('GOOGLE_API_KEY', 'YOUR_GEMINI_API_KEY')\n",
    "\n",
    "print(f\"‚úì Project root: {project_root}\")\n",
    "print(f\"‚úì Python path configured\")\n",
    "print(f\"‚úì API key: {'set' if os.environ.get('GOOGLE_API_KEY') != 'YOUR_GEMINI_API_KEY' else 'NOT SET'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b406d17",
   "metadata": {},
   "source": [
    "## Part 1: Initialize Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from agents_capstone.agents.vision_agent import VisionAgent\n",
    "from agents_capstone.agents.knowledge_agent import KnowledgeAgent\n",
    "from agents_capstone.agents.orchestrator import Orchestrator\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "\n",
    "# Create agents\n",
    "vision_agent = VisionAgent()\n",
    "knowledge_agent = KnowledgeAgent()\n",
    "orchestrator = Orchestrator(vision_agent, knowledge_agent)\n",
    "\n",
    "print(\"‚úì VisionAgent initialized\")\n",
    "print(\"‚úì KnowledgeAgent initialized\")\n",
    "print(\"‚úì Orchestrator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b252b",
   "metadata": {},
   "source": [
    "## Part 2: Vision Agent ‚Äì Analyze a Photo\n",
    "\n",
    "The VisionAgent uses Gemini Vision to:\n",
    "1. Extract EXIF metadata (camera, settings)\n",
    "2. Analyze composition (rule of thirds, focal points, etc.)\n",
    "3. Identify potential issues (centered subject, underexposure, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo, assume an uploaded image exists (from Streamlit app)\n",
    "# If not, we'll create a placeholder flow\n",
    "\n",
    "test_image_path = \"/Users/prasadt1/ai-photography-coach-rag/tmp_uploaded.jpg\"\n",
    "\n",
    "if os.path.exists(test_image_path):\n",
    "    print(f\"Analyzing image: {test_image_path}\")\n",
    "    vision_result = vision_agent.analyze(test_image_path, skill_level=\"beginner\")\n",
    "    \n",
    "    print(\"\\nüìä EXIF Metadata:\")\n",
    "    for key, val in vision_result.exif.items():\n",
    "        print(f\"  {key}: {val}\")\n",
    "    \n",
    "    print(f\"\\nüìê Composition Summary:\")\n",
    "    print(f\"  {vision_result.composition_summary}\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Identified Issues:\")\n",
    "    for issue in vision_result.issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(f\"‚ùå Test image not found: {test_image_path}\")\n",
    "    print(\"\\nTo test, upload a photo via the Streamlit app first:\")\n",
    "    print(\"  python3 -m streamlit run agents_capstone/app_streamlit.py\")\n",
    "    \n",
    "    # Show a demo structure\n",
    "    print(\"\\nüìã VisionAnalysis structure (demo):\")\n",
    "    print(\"\"\"{\n",
    "  exif: {\n",
    "    Model: \"iPhone 11 Pro Max\",\n",
    "    FocalLength: 4.25,\n",
    "    FNumber: 1.8,\n",
    "    ExposureTime: 0.03,\n",
    "    ISOSpeedRatings: 500\n",
    "  },\n",
    "  composition_summary: \"The photo has good leading lines...\",\n",
    "  issues: [\"subject_centered\", \"high_iso\"]\n",
    "}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf09b1",
   "metadata": {},
   "source": [
    "## Part 3: Multi-Turn Coaching via Orchestrator\n",
    "\n",
    "The Orchestrator coordinates agents and manages session state:\n",
    "1. Loads/creates a session for the user\n",
    "2. Runs VisionAgent (cached after first call)\n",
    "3. Runs KnowledgeAgent with session history\n",
    "4. Persists session for next turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo orchestrator flow (if image is available)\n",
    "if os.path.exists(test_image_path):\n",
    "    user_id = \"demo_user\"\n",
    "    \n",
    "    # First turn: ask about composition\n",
    "    query1 = \"How can I improve the composition of this photo?\"\n",
    "    print(f\"\\nüó£Ô∏è  User: {query1}\")\n",
    "    \n",
    "    result1 = orchestrator.run(\n",
    "        user_id=user_id,\n",
    "        image_path=test_image_path,\n",
    "        query=query1\n",
    "    )\n",
    "    \n",
    "    coach_text = result1.get(\"coach\", {}).get(\"text\")\n",
    "    print(f\"\\nüéØ Coach: {coach_text[:300]}...\")\n",
    "    \n",
    "    # Second turn: follow-up question (no image needed)\n",
    "    query2 = \"What is ISO and how does it affect image quality?\"\n",
    "    print(f\"\\nüó£Ô∏è  User: {query2}\")\n",
    "    \n",
    "    result2 = orchestrator.run(\n",
    "        user_id=user_id,\n",
    "        image_path=None,  # No new image, use session context\n",
    "        query=query2\n",
    "    )\n",
    "    \n",
    "    coach_text2 = result2.get(\"coach\", {}).get(\"text\")\n",
    "    print(f\"\\nüéØ Coach: {coach_text2[:300]}...\")\n",
    "    \n",
    "    # Show session state\n",
    "    session = result2.get(\"session\", {})\n",
    "    print(f\"\\nüìù Session State:\")\n",
    "    print(f\"  User ID: {user_id}\")\n",
    "    print(f\"  Skill Level: {session.get('skill_level')}\")\n",
    "    print(f\"  History Length: {len(session.get('history', []))} turns\")\n",
    "    if session.get('compact_summary'):\n",
    "        print(f\"  Compact Summary: {session.get('compact_summary')[:100]}...\")\n",
    "else:\n",
    "    print(\"(Orchestrator demo requires an uploaded image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d5d04",
   "metadata": {},
   "source": [
    "## Part 4: Session & Memory Management\n",
    "\n",
    "The ADK adapter transparently manages persistent memory:\n",
    "- Detects ADK's InMemorySessionService if available\n",
    "- Falls back to SQLite persistence otherwise\n",
    "- Stores session state, chat history, and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d52b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents_capstone.tools import adk_adapter\n",
    "\n",
    "print(f\"Using ADK: {adk_adapter.USING_ADK}\")\n",
    "print(f\"Backend: {'ADK InMemorySessionService' if adk_adapter.USING_ADK else 'SQLite'}\")\n",
    "\n",
    "# Initialize storage\n",
    "adk_adapter.init()\n",
    "\n",
    "# Test persistence\n",
    "test_user = \"test_session_user\"\n",
    "test_data = {\"skill_level\": \"advanced\", \"history\": [{\"msg\": \"test\"}]}\n",
    "\n",
    "adk_adapter.set_value(test_user, \"session\", test_data)\n",
    "retrieved = adk_adapter.get_value(test_user, \"session\")\n",
    "\n",
    "print(f\"\\n‚úì Stored: {test_data}\")\n",
    "print(f\"‚úì Retrieved: {retrieved}\")\n",
    "print(f\"‚úì Match: {retrieved == test_data}\")\n",
    "\n",
    "# Show database location\n",
    "if not adk_adapter.USING_ADK:\n",
    "    db_path = \"/Users/prasadt1/ai-photography-coach-rag/agents_memory.db\"\n",
    "    if os.path.exists(db_path):\n",
    "        size_mb = os.path.getsize(db_path) / (1024 * 1024)\n",
    "        print(f\"\\nüì¶ Database: {db_path} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4254b",
   "metadata": {},
   "source": [
    "## Part 5: Evaluation with LLM-as-Judge\n",
    "\n",
    "The evaluation harness scores agent responses on:\n",
    "- **Relevance**: Does it address the user's question?\n",
    "- **Completeness**: Sufficient detail and context?\n",
    "- **Accuracy**: Is technical advice correct?\n",
    "- **Actionability**: Can user act on this immediately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents_capstone.evaluate import evaluate_sample\n",
    "\n",
    "# Sample test prompts\n",
    "test_prompts = [\n",
    "    \"How can I improve the composition of this photo?\",\n",
    "    \"What camera settings should I use for a sunset shot?\",\n",
    "    \"Explain the rule of thirds and how to apply it.\",\n",
    "]\n",
    "\n",
    "if os.path.exists(test_image_path):\n",
    "    print(\"Running evaluation on test prompts...\")\n",
    "    print(\"(This may take a minute with LLM-as-Judge scoring)\\n\")\n",
    "    \n",
    "    summary = evaluate_sample(\n",
    "        image_path=test_image_path,\n",
    "        prompts=test_prompts,\n",
    "        out_dir=\"reports\",\n",
    "        use_llm_judge=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Evaluation Results:\")\n",
    "    print(f\"  Avg Overall Score: {summary['avg_overall_score']}/10\")\n",
    "    print(f\"  Avg Latency: {summary['avg_latency_sec']:.2f}s\")\n",
    "    print(f\"  Prompts Evaluated: {summary['num_prompts']}\")\n",
    "    \n",
    "    # Show sample result\n",
    "    if summary['results']:\n",
    "        first = summary['results'][0]\n",
    "        print(f\"\\n  Sample Result:\")\n",
    "        print(f\"    Prompt: {first['prompt']}\")\n",
    "        print(f\"    Score: {first['overall_score']}\")\n",
    "        if first['llm_scores']:\n",
    "            print(f\"    Relevance: {first['llm_scores'].get('relevance')}\")\n",
    "else:\n",
    "    print(\"(Evaluation demo requires an uploaded image)\")\n",
    "    print(\"\\nTo run evaluation after testing:\")\n",
    "    print(\"  from agents_capstone.evaluate import evaluate_sample\")\n",
    "    print(\"  summary = evaluate_sample('path/to/image.jpg', test_prompts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e7ab4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the **AI Photography Coach** capstone project, showcasing:\n",
    "\n",
    "‚úÖ **Multi-Agent Architecture** (Day 1)\n",
    "   - VisionAgent (Gemini Vision + EXIF) ‚Üí KnowledgeAgent (coaching) via Orchestrator\n",
    "\n",
    "‚úÖ **Agent Tools** (Day 2)\n",
    "   - EXIF extraction tool, knowledge base tool\n",
    "   - Tools structured as ADK-compatible definitions\n",
    "\n",
    "‚úÖ **Context Engineering** (Day 3)\n",
    "   - Session management (in-memory + persistent)\n",
    "   - Multi-turn conversation history\n",
    "   - Context compaction for long histories\n",
    "\n",
    "‚úÖ **Agent Quality** (Day 4)\n",
    "   - Structured logging (JSON format)\n",
    "   - Observability panel in UI\n",
    "   - LLM-as-Judge evaluation framework\n",
    "\n",
    "‚úÖ **Prototype to Production** (Day 5)\n",
    "   - Streamlit web demo\n",
    "   - Docker containerization\n",
    "   - ADK-ready architecture for cloud deployment\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Run the Streamlit app locally:**\n",
    "   ```bash\n",
    "   export GOOGLE_API_KEY=\"YOUR_GEMINI_KEY\"\n",
    "   python3 -m streamlit run agents_capstone/app_streamlit.py\n",
    "   ```\n",
    "\n",
    "2. **Run evaluation on a test image:**\n",
    "   ```bash\n",
    "   cd agents_capstone\n",
    "   python3 evaluate.py\n",
    "   ```\n",
    "\n",
    "3. **Deploy with Docker:**\n",
    "   ```bash\n",
    "   docker build -t photo-coach:latest .\n",
    "   docker run -e GOOGLE_API_KEY=\"YOUR_KEY\" -p 8501:8501 photo-coach:latest\n",
    "   ```\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- üìñ **WRITEUP.md** ‚Äì Full rubric mapping and submission checklist\n",
    "- üìã **ADK_INTEGRATION.md** ‚Äì ADK setup and integration guide\n",
    "- üìä **OBSERVABILITY.md** ‚Äì Logs, traces, metrics reference\n",
    "- üê≥ **Dockerfile** ‚Äì Production-ready container image\n",
    "\n",
    "---\n",
    "\n",
    "**Built for:** Google AI Agents Intensive ‚Äì Capstone Project"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
